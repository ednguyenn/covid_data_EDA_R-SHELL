# Convert the predicted labels to factor
y_pred <- factor(y_pred, levels = levels(y_test))
# Evaluate the model
conf_matrix <- confusionMatrix(y_pred, y_test)
accuracy <- conf_matrix$overall['Accuracy']
f1_score <- conf_matrix$byClass['F1']
# Print the evaluation metrics
print(paste("Accuracy:", round(accuracy, 4)))
print(paste("F1 Score:", round(f1_score, 4)))
print("Confusion Matrix:")
print(conf_matrix$table)
df_clean <- na.omit(df)
#feature importance
importance_scores <- tree_model_1$variable.importance
# convert importance scores to a data frame
importance_df <- data.frame(Feature = names(importance_scores), Importance = importance_scores)
importance_df <- importance_df[order(-importance_df$Importance),]
print("feature Importance:")
print(importance_df)
# select top features bases on threshold = 0.4
top_features <- rownames(importance_df[importance_df$Importance > 0.4, ])
# Create training data with selected features
train_data_2 <- create_train_test(df_clean[, c(top_features, "relevanceJudge")], size = 0.8, train = TRUE)
# Create testing data with selected features
test_data_2 <- create_train_test(df_clean[, c(top_features, "relevanceJudge")], size = 0.8, train = FALSE)
# calculate new variables
# variable: interaction between text_score and text_score_expansion
train_data_2$interaction_text_score_expansion <- train_data_2$text_score * train_data_2$text_score_expansion
test_data_2$interaction_text_score_expansion <- test_data_2$text_score * test_data_2$text_score_expansion
# variable: tweet_frequency
train_data_2$tweet_frequency <- train_data_2$X.tweetsPosted / train_data_2$twitterAge
#feature importance
importance_scores <- tree_model_1$variable.importance
# convert importance scores to a data frame
importance_df <- data.frame(Feature = names(importance_scores), Importance = importance_scores)
importance_df <- importance_df[order(-importance_df$Importance),]
print("feature Importance:")
print(importance_df)
# select top features bases on threshold = 0.2
top_features <- rownames(importance_df[importance_df$Importance > 0.2, ])
# Create training data with selected features
train_data_2 <- create_train_test(df_clean[, c(top_features, "relevanceJudge")], size = 0.8, train = TRUE)
# Create testing data with selected features
test_data_2 <- create_train_test(df_clean[, c(top_features, "relevanceJudge")], size = 0.8, train = FALSE)
# calculate new variables
# variable: interaction between text_score and text_score_expansion
train_data_2$interaction_text_score_expansion <- train_data_2$text_score * train_data_2$text_score_expansion
test_data_2$interaction_text_score_expansion <- test_data_2$text_score * test_data_2$text_score_expansion
# variable: tweet_frequency
train_data_2$tweet_frequency <- train_data_2$X.tweetsPosted / train_data_2$twitterAge
names(train_data_2)
names(test_data_2)
# calculate new variables
# variable: interaction between text_score and text_score_expansion
train_data_2$interaction_text_score_expansion <- train_data_2$text_score * train_data_2$text_score_expansion
test_data_2$interaction_text_score_expansion <- test_data_2$text_score * test_data_2$text_score_expansion
# variable: likes_per_follower variable to testing data
train_data_2$likes_per_follower <- train_data_2$nFavorties / (train_data_2$nFollowers + 1)
# calculate new variables
# variable: interaction between text_score and text_score_expansion
train_data_2$interaction_text_score_expansion <- train_data_2$text_score * train_data_2$text_score_expansion
test_data_2$interaction_text_score_expansion <- test_data_2$text_score * test_data_2$text_score_expansion
# variable: interaction has URL
train_data_2$interaction_score_hasURL <- train_data_2$text_score * train_data_2$hasURL
test_data_2$interaction_score_hasURL <- test_data_2$text_score * test_data_2$hasURL
# variable: squared_length
train_data_2$length_squared <- train_data_2$length^2
test_data_2$length_squared <- test_data_2$length^2
# Train the decision tree model with selected and engineered features
tree_model_2 <- rpart(relevanceJudge ~ ., data = train_data_2, method = "class")
# Make predictions on the test data
y_pred_2 <- predict(tree_model_2, test_data_2, type = "class")
# Convert the true labels in the test data to factor
y_test_2 <- as.factor(test_data_2$relevanceJudge)
# Convert the predicted labels to factor
y_pred_2 <- factor(y_pred_2, levels = levels(y_test_2))
# Evaluate the model
conf_matrix_2 <- confusionMatrix(y_pred_2, y_test_2)
accuracy_2 <- conf_matrix_2$overall['Accuracy']
f1_score_2 <- conf_matrix_2$byClass['F1']
# Print the evaluation metrics
print(paste("Accuracy:", round(accuracy_2, 4)))
print(paste("F1 Score:", round(f1_score_2, 4)))
print("Confusion Matrix:")
print(conf_matrix_2$table)
# calculate new variables
# variable: interaction between text_score and text_score_expansion
train_data_2$interaction_text_score_expansion <- train_data_2$text_score * train_data_2$text_score_expansion
test_data_2$interaction_text_score_expansion <- test_data_2$text_score * test_data_2$text_score_expansion
# variable: interaction has URL
train_data_2$interaction_score_hasURL <- train_data_2$text_score * train_data_2$hasURL
test_data_2$interaction_score_hasURL <- test_data_2$text_score * test_data_2$hasURL
# variable: squared_length
train_data_2$length_squared <- train_data_2$length^2
test_data_2$length_squared <- test_data_2$length^2
# training new model and make prediction
tree_model_2 <- rpart(relevanceJudge ~ ., data = train_data_2, method = "class")
y_pred_2 <- predict(tree_model_2, test_data_2, type = "class")
# Convert the true labels in the test data to factor
y_test_2 <- as.factor(test_data_2$relevanceJudge)
y_pred_2 <- factor(y_pred_2, levels = levels(y_test_2))
# Evaluate the model
conf_matrix_2 <- confusionMatrix(y_pred_2, y_test_2)
accuracy_2 <- conf_matrix_2$overall['Accuracy']
f1_score_2 <- conf_matrix_2$byClass['F1']
# Print the evaluation metrics
print(paste("Accuracy:", round(accuracy_2, 4)))
print(paste("F1 Score:", round(f1_score_2, 4)))
print("Confusion Matrix:")
print(conf_matrix_2$table)
# Read the CSV file
olympics_tweets <- read.csv("Olympics_tweets.csv")
str(olympics_tweets)
summary(olympics_tweets)
rm(list=ls())
library(lubridate)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(caret)
library(rpart)
library(rpart.plot)
theme_set(theme_classic())
# read  and save 3 datasets
covid_data <- read.csv("Covid-data.csv")
lockdown_data <- read.csv("CountryLockdowndates.csv")
vaccine_data <- read.csv("WorldwideVaccineData.csv")
# Display the structure of the datasets
str(covid_data)
str(lockdown_data)
str(vaccine_data)
convert_dates <- function(dates) {
converted_dates <- vector("character", length(dates))
# using regex pattern
pattern <- "^(\\d{4})-(\\d{2})-(\\d{2})$"
# Loop through each date to extract Y D M
for (i in seq_along(dates)) {
# Check if date matches the pattern
if (grepl(pattern, dates[i])) {
YYYY <- substr(dates[i], 1, 4)
MM <- substr(dates[i], 6, 7)
DD <- substr(dates[i], 9, 10)
# Check if MM > 12, then switch with DD
if (as.numeric(MM) > 12) {
temp <- MM
MM <- DD
DD <- temp
}
# Format the date into YYYY-MM-DD
converted_dates[i] <- paste(YYYY, MM, DD, sep = "-")
} else {
converted_dates[i] <- NA
}
}
return(converted_dates)
}
# Applying to the function to dataset
covid_data$date <- convert_dates(covid_data$date)
# Convert Date column to Date object using lubricate library
lockdown_data$Date <- dmy(lockdown_data$Date)
# Format Date column to YYYY-MM-DD
lockdown_data$Date <- format(lockdown_data$Date, "%Y-%m-%d")
summary(covid_data)
# Remove rows with NA values
covid_data <- covid_data[!apply(is.na(covid_data), 1, any), ]
str(covid_data)
# Convert negative values to positive in new_cases and new_deaths columns
covid_data$new_cases <- abs(covid_data$new_cases)
covid_data$new_deaths <- abs(covid_data$new_deaths)
unique_locations <- unique(covid_data$location)
print(unique_locations)
#create a data frame that maps inconsistent location names to standardized names
location_mapping <- data.frame(
original = c("Australia", "Australia  ", "China", " China", "France", "Iran", "iran", "Italy", "Itly", "Spain", "United Kingdom", "UnitedKingdom", "United States", "United Stats"),
standardized = c("Australia", "Australia", "China", "China", "France", "Iran", "Iran", "Italy", "Italy", "Spain", "United Kingdom", "United Kingdom", "United States", "United States")
)
#Create a function to standardize the location names based on the mapping
standardize_location <- function(df, column_name, mapping_df) {
df[[column_name]] <- mapping_df$standardized[match(df[[column_name]], mapping_df$original)]
df[[column_name]][is.na(df[[column_name]])] <- df[[column_name]][is.na(df[[column_name]])]
return(df)
}
covid_data <- standardize_location(covid_data, "location", location_mapping)
summary(lockdown_data)
# Count empty strings in Province and Date columns
empty_province <- sum(lockdown_data$Province == "")
cat("Empty strings in Province column:", empty_province, "\n")
lockdown_aggregated <- lockdown_data %>%
group_by(Country.Region) %>%
summarize(Date = first(na.omit(Date))) %>%
ungroup() %>%
rename(Country = Country.Region)
summary(vaccine_data)
vaccine_data <- vaccine_data %>%
rename(
Country = Country,
`Doses Administered` = Doses.administered.per.100.people,
`Total Doses Administered` = Total.doses.administered,
`% of Population Vaccinated` = X..of.population.vaccinated,
`% of Population Fully Vaccinated` = X..of.population.fully.vaccinated
)
# Check the cleaned data
str(vaccine_data)
summary(vaccine_data)
unique_locations <- unique(covid_data$location)
print(unique_locations)
# fix 'US' to 'United States' in lockdown_aggregated
lockdown_aggregated$Country[lockdown_aggregated$Country == "US"] <- "United States"
# fix 'U.K.' to 'United Kingdom' in vaccine_data
vaccine_data$Country[vaccine_data$Country == "U.K."] <- "United Kingdom"
colnames_vaccine_data <- colnames(vaccine_data)
print(colnames_vaccine_data)
library(dplyr)
# Ensure consistent column names
covid_data <- covid_data %>%
rename(Country = location)
lockdown_data <- lockdown_data %>%
rename(Country = Country.Region)
# Perform left joins
joined_data <- covid_data %>%
left_join(lockdown_aggregated, by = "Country") %>%
left_join(vaccine_data, by = "Country") %>%
select(
Country, date, total_cases, new_cases, total_deaths, new_deaths,
gdp_per_capita, population, Date,
'Total Doses Administered','% of Population Fully Vaccinated'
)
# Rename Country back to location for consistency with the desired column names
joined_data <- joined_data %>%
rename(location = Country,
lockdown_date = Date)
# taking a look at a joined_dataset
str(joined_data)
summary(joined_data)
joined_data$date <- as.Date(joined_data$date)
joined_data$lockdown_date <- as.Date(joined_data$lockdown_date)
# Check for duplicates in joined_data
duplicates <- joined_data[duplicated(joined_data), ]
# Print the duplicate rows if any
if (nrow(duplicates) > 0) {
print("Duplicate rows found:")
print(duplicates)
} else {
print("No duplicate rows found.")
}
library(ggplot2)
#Plotting new cases trend for each country
ggplot(data = joined_data, aes(x = date, y = new_cases, group = location, color = location)) +
geom_line() +
scale_x_date(date_labels = "%b %Y", date_breaks = "1 month") +
labs(title = "Trend of New COVID-19 Cases by Country",
x = "Date", y = "New Cases") +
theme_minimal()
#Plotting new cases trend for each country with lockdown dates
ggplot(data = joined_data, aes(x = date, y = new_cases, group = location, color = location)) +
geom_line() +
scale_x_date(date_labels = "%b %Y", date_breaks = "1 month") +
labs(title = "Trend of New COVID-19 Cases by Country",
x = "Date", y = "New Cases") +
theme_minimal() +
facet_wrap(~ location, scales = "free_y", ncol = 3) +
geom_vline(data = joined_data, aes(xintercept = as.numeric(as.Date(lockdown_date))),
linetype = "dashed", color = "red", alpha = 0.5) +  # Add vertical lines for lockdown dates
guides(color = guide_legend(title = "Country")) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Remove row 1357 from joined_data which contains a abnormal value
joined_data <- joined_data[-1357, ]
# calculation of the mean GDP to split status
mean_gdp <- mean(joined_data$gdp_per_capita, na.rm = TRUE)
#Add a column 'GDP_Status'
joined_data <- joined_data %>%
mutate(GDP_Status = ifelse(gdp_per_capita >= mean_gdp, "High GDP", "Low GDP"))
#Calculate the daily infected case rate and daily death rate
joined_data <- joined_data %>%
mutate(daily_infected_case_rate = new_cases / population,
daily_death_rate = new_deaths / population)
# Bar plot for daily infected case rate
infected_case_plot <- ggplot(joined_data, aes(x = date, y = daily_infected_case_rate, fill = GDP_Status)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Daily Infected Case Rate by GDP Status",
x = "Date",
y = "Daily Infected Case Rate") +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
# Bar plot for daily death rate
death_rate_plot <- ggplot(joined_data, aes(x = date, y = daily_death_rate, fill = GDP_Status)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Daily Death Rate by GDP Status",
x = "Date",
y = "Daily Death Rate") +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
print(infected_case_plot)
print(death_rate_plot)
# Filter the data for Australia only
australia_data <- joined_data %>% filter(location == "Australia")
# Convert dates to numeric starting from 0 for poly model
australia_data$numeric_date <- as.numeric(australia_data$date - min(australia_data$date))
# Plot the data
ggplot(australia_data, aes(x = numeric_date, y = new_cases)) +
geom_point(color = "blue") +
scale_x_continuous(breaks = scales::pretty_breaks(n = 10), labels = scales::date_format("%b %Y")) +
labs(title = "Trend of New COVID-19 Cases in Australia",
x = "Date", y = "New Cases") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Fit a polynomial regression model
model <- lm(new_cases ~ poly(numeric_date, 7, raw = TRUE), data = australia_data)
# Generate 7 dates
last_date <- max(australia_data$date)
future_dates <- seq.Date(from = last_date + 1, by = "day", length.out = 7)
future_numeric_dates <- as.numeric(future_dates - min(australia_data$date))
# Predict new case
future_predictions <- predict(model, newdata = data.frame(numeric_date = future_numeric_dates))
# Combine future dates with predictions so we can plot the prediction data
future_predictions_df <- data.frame(date = future_dates, new_cases = future_predictions)
# Plot the data and the predictions
ggplot(australia_data, aes(x = date, y = new_cases)) +
geom_line(color = "blue") +
geom_point(data = future_predictions_df, aes(x = date, y = new_cases), color = "red") +
geom_line(data = future_predictions_df, aes(x = date, y = new_cases), color = "red", linetype = "dashed") +
scale_x_date(date_labels = "%b %Y", date_breaks = "1 month") +
labs(title = "Trend and Predictions of New COVID-19 Cases in Australia",
x = "Date", y = "New Cases") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Split the data into training and test set with an 90:10 split ratio
set.seed(123)
training.samples <- australia_data %>%
dplyr::select(date) %>%
mutate(id = row_number()) %>%
sample_frac(0.9) %>%
pull(id)
train.data <- australia_data[training.samples, ]
test.data <- australia_data[-training.samples, ]
# Make predictions
train.data$predictions <- predict(model, newdata = train.data)
test.data$predictions <- predict(model, newdata = test.data)
# Compute performance metrics
performance_train <- data.frame(
RMSE = RMSE(train.data$predictions, train.data$new_cases),
R2 = R2(train.data$predictions, train.data$new_cases)
)
performance_test <- data.frame(
RMSE = RMSE(test.data$predictions, test.data$new_cases),
R2 = R2(test.data$predictions, test.data$new_cases)
)
# Visualize the performance on both sets
ggplot() +
geom_line(data = train.data, aes(x = date, y = new_cases), color = "blue") +
geom_line(data = train.data, aes(x = date, y = predictions), color = "red", linetype = "dashed") +
geom_line(data = test.data, aes(x = date, y = new_cases), color = "green") +
geom_line(data = test.data, aes(x = date, y = predictions), color = "purple", linetype = "dashed") +
scale_x_date(date_labels = "%b %Y", date_breaks = "1 month") +
labs(title = "Model Performance on Training and Test Sets",
x = "Date", y = "New Cases") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
#10-fold cross-validation
set.seed(123)
train_control <- trainControl(method = "cv", number = 10)
cv_model <- train(new_cases ~ poly(date, 7, raw = TRUE), data = australia_data,
method = "lm", trControl = train_control)
# Cross-validated performance metrics
performance_cv <- data.frame(
RMSE = cv_model$results$RMSE,
R2 = cv_model$results$Rsquared
)
print("Performance on Training Set:")
print(performance_train)
print("Performance on Test Set:")
print(performance_test)
print("Performance with K-fold Cross-Validation:")
print(performance_cv)
# Read the CSV file
olympics_tweets <- read.csv("Olympics_tweets.csv")
str(olympics_tweets)
summary(olympics_tweets)
# Convert user_created_at to Date-Time
olympics_tweets$user_created_at <- dmy_hm(olympics_tweets$user_created_at)
# extract the year and add it as a new variable
olympics_tweets$user_created_at_year <- year(olympics_tweets$user_created_at)
# Filter data for users created after 2010
filtered_data <- olympics_tweets %>%
filter(user_created_at_year > 2010)
# Calculate the average number of user_followers for each year
average_followers_per_year <- filtered_data %>%
group_by(user_created_at_year) %>%
summarise(average_followers = mean(user_followers, na.rm = TRUE))
# we plot the average number of user_followers across different year
ggplot(average_followers_per_year, aes(x = factor(user_created_at_year), y = average_followers)) +
geom_bar(stat = "identity", fill = "skyblue") +
labs(title = "Average Number of Followers for Users Created After 2010",
x = "Year", y = "Average Number of Followers") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Count occurrences of different location values, excluding NA
location_counts <- olympics_tweets %>%
filter(!is.na(user_location)) %>%
count(user_location, sort = TRUE)
# Display the top 10 most frequent location values
top_10_locations <- location_counts %>%
top_n(10, n)
# Print the top 10 locations and their counts
print(top_10_locations)
# Calculate the total number of tweets associated with the top 10 locations
total_tweets_top_10 <- sum(top_10_locations$n)
# Print the total number of tweets
print(total_tweets_top_10)
# calculation of the length of the text in each tweet
olympics_tweets <- olympics_tweets %>%
mutate(text_length = nchar(text))
# Define length categories
olympics_tweets <- olympics_tweets %>%
mutate(length_category = case_when(
text_length >= 1 & text_length <= 40 ~ "[1, 40]",
text_length >= 41 & text_length <= 80 ~ "[41, 80]",
text_length >= 81 & text_length <= 120 ~ "[81, 120]",
text_length >= 121 & text_length <= 160 ~ "[121, 160]",
text_length >= 161 & text_length <= 200 ~ "[161, 200]",
text_length >= 201 & text_length <= 240 ~ "[201, 240]",
text_length >= 241 ~ ">= 241"
))
# Count the number of tweets in each length category
length_counts <- olympics_tweets %>%
count(length_category, sort = TRUE)
# Plot the bar chart
ggplot(length_counts, aes(x = length_category, y = n, fill = length_category)) +
geom_bar(stat = "identity") +
scale_x_discrete(limits = c("[1, 40]", "[41, 80]", "[81, 120]", "[121, 160]", "[161, 200]", "[201, 240]", ">= 241")) +
labs(title = "Number of Tweets by Text Length",
x = "Text Length (Characters)",
y = "Number of Tweets") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Read the CSV file
df <- read.csv("predictive_twitter_data.csv")
summary(df)
create_train_test <- function(data, size = 0.8, train = TRUE) {
n_row <- nrow(data)
total_row <- floor(size * n_row)
train_indices <- sample(1:n_row, total_row, replace = FALSE)
if (train) {
# Return training data
return(data[train_indices, ])
} else {
# Return testing data
return(data[-train_indices, ])
}
}
# Create training and testing data
train_data <- create_train_test(df, size = 0.8, train = TRUE)
test_data <- create_train_test(df, size = 0.8, train = FALSE)
tree_model_1 <- rpart(relevanceJudge ~ ., data = train_data, method = "class")
y_pred <- predict(tree_model_1, test_data, type = "class")
# Convert the true labels in the test data to factor
y_test <- as.factor(test_data$relevanceJudge)
# Convert the predicted labels to factor
y_pred <- factor(y_pred, levels = levels(y_test))
# Evaluate the model
conf_matrix <- confusionMatrix(y_pred, y_test)
accuracy <- conf_matrix$overall['Accuracy']
f1_score <- conf_matrix$byClass['F1']
# Print the evaluation metrics
print(paste("Accuracy:", round(accuracy, 4)))
print(paste("F1 Score:", round(f1_score, 4)))
print("Confusion Matrix:")
print(conf_matrix$table)
df_clean <- na.omit(df)
#feature importance
importance_scores <- tree_model_1$variable.importance
# convert importance scores to a data frame
importance_df <- data.frame(Feature = names(importance_scores), Importance = importance_scores)
importance_df <- importance_df[order(-importance_df$Importance),]
print("feature Importance:")
print(importance_df)
# select top features bases on threshold = 0.2
top_features <- rownames(importance_df[importance_df$Importance > 0.2, ])
# Create training data with selected features
train_data_2 <- create_train_test(df_clean[, c(top_features, "relevanceJudge")], size = 0.8, train = TRUE)
# Create testing data with selected features
test_data_2 <- create_train_test(df_clean[, c(top_features, "relevanceJudge")], size = 0.8, train = FALSE)
names(train_data_2)
names(test_data_2)
# calculate new variables
# variable: interaction between text_score and text_score_expansion
train_data_2$interaction_text_score_expansion <- train_data_2$text_score * train_data_2$text_score_expansion
test_data_2$interaction_text_score_expansion <- test_data_2$text_score * test_data_2$text_score_expansion
# variable: interaction has URL
train_data_2$interaction_score_hasURL <- train_data_2$text_score * train_data_2$hasURL
test_data_2$interaction_score_hasURL <- test_data_2$text_score * test_data_2$hasURL
# variable: squared_length
train_data_2$length_squared <- train_data_2$length^2
test_data_2$length_squared <- test_data_2$length^2
# training new model and make prediction
tree_model_2 <- rpart(relevanceJudge ~ ., data = train_data_2, method = "class")
y_pred_2 <- predict(tree_model_2, test_data_2, type = "class")
# convert the true labels in the test data to factor
y_test_2 <- as.factor(test_data_2$relevanceJudge)
y_pred_2 <- factor(y_pred_2, levels = levels(y_test_2))
# Evaluate new model
conf_matrix_2 <- confusionMatrix(y_pred_2, y_test_2)
accuracy_2 <- conf_matrix_2$overall['Accuracy']
f1_score_2 <- conf_matrix_2$byClass['F1']
#evaluation metrics
print(paste("Accuracy:", round(accuracy_2, 4)))
print(paste("F1 Score:", round(f1_score_2, 4)))
print("Confusion Matrix:")
print(conf_matrix_2$table)
# Read the CSV file
olympics_tweets <- read.csv("Olympics_tweets.csv")
str(olympics_tweets)
summary(olympics_tweets)
View(olympics_tweets)
